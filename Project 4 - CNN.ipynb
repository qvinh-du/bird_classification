{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e417aa7",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458b76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, preprocessing\n",
    "from keras.preprocessing import image \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d92b95",
   "metadata": {},
   "source": [
    "DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e65bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test to check if input folder images is detected\n",
    "#print(os.listdir('input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee78558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories\n",
    "train_dir = 'input/train'\n",
    "valid_dir = 'input/valid'\n",
    "test_dir = 'input/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf7225",
   "metadata": {},
   "source": [
    "BIRD CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f15f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test to check if the 15 bird classes are detected\n",
    "#print(os.listdir(train_dir))\n",
    "#print(os.listdir(test_dir))\n",
    "#print(os.listdir(valid_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7647609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bird classes identification\n",
    "bird_classes = os.listdir(train_dir)\n",
    "#Test to check the names of the 15 bird classes\n",
    "#print(str(len(bird_classes)),'The chosen 15 classes are ', bird_classes)\n",
    "\n",
    "num_classes = len(bird_classes)\n",
    "#Test to verify we have the correct amount of bird classes in each folder\n",
    "#print(len(os.listdir(train_dir)))\n",
    "#print(len(os.listdir(test_dir)))\n",
    "#print(len(os.listdir(valid_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec37cf",
   "metadata": {},
   "source": [
    "IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d88bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensions of image and input shapes\n",
    "image_size = (224,224)\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "#Batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5534646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy arrays of the images of the training dataset\n",
    "x_train=[]\n",
    "for folder in os.listdir(train_dir):\n",
    "    sub_path=train_dir+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,image_size)\n",
    "        x_train.append(img_arr)\n",
    "\n",
    "#Numpy arrays of the images of the testing dataset\n",
    "x_test=[]\n",
    "for folder in os.listdir(test_dir):\n",
    "    sub_path=test_dir+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,image_size)\n",
    "        x_test.append(img_arr)\n",
    "\n",
    "#Numpy arrays of the images of the validation dataset\n",
    "x_valid=[]\n",
    "for folder in os.listdir(valid_dir):\n",
    "    sub_path=valid_dir+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        img_arr=cv2.imread(image_path)\n",
    "        img_arr=cv2.resize(img_arr,image_size)\n",
    "        x_valid.append(img_arr)\n",
    "\n",
    "#Normalization of arrays\n",
    "train_x = np.array(x_train)\n",
    "test_x = np.array(x_test)\n",
    "valid_x = np.array(x_valid)\n",
    "train_x = train_x/255.0\n",
    "test_x = test_x/255.0\n",
    "valid_x = valid_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3e0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale images\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4c5e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2173 images belonging to 15 classes.\n",
      "Found 75 images belonging to 15 classes.\n",
      "Found 75 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "#Read training images\n",
    "train_data = train_datagen.flow_from_directory(train_dir, target_size = image_size, batch_size = batch_size)\n",
    "test_data = test_datagen.flow_from_directory(test_dir, target_size = image_size, batch_size = batch_size)\n",
    "valid_data = valid_datagen.flow_from_directory(valid_dir, target_size = image_size, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8103d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.classes\n",
    "test_y = test_data.classes\n",
    "valid_y = valid_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e8b408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ABBOTTS BABBLER': 0,\n",
       " 'BAIKAL TEAL': 1,\n",
       " 'CACTUS WREN': 2,\n",
       " 'DARK EYED JUNCO': 3,\n",
       " 'EARED PITA': 4,\n",
       " 'FAIRY BLUEBIRD': 5,\n",
       " 'GAMBELS QUAIL': 6,\n",
       " 'HAMMERKOP': 7,\n",
       " 'IBERIAN MAGPIE': 8,\n",
       " 'JABIRU': 9,\n",
       " 'KAGU': 10,\n",
       " 'LARK BUNTING': 11,\n",
       " 'MAGPIE GOOSE': 12,\n",
       " 'NICOBAR PIGEON': 13,\n",
       " 'OCELLATED TURKEY': 14}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc403fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2173,), (75,), (75,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape,test_y.shape,valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c91bd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing and previewing the training data\n",
    "#list_bird_classes = list(train_generator.class_indices.keys())\n",
    "#x = list(train_generator.classes)\n",
    "\n",
    "#list_num_training_img = []\n",
    "\n",
    "#for i in range (0,num_classes):\n",
    "    #list_num_training_img.append(x.count(i))\n",
    "    \n",
    "#print('Number of training images per class varies between: ' + str(max(list_num_training_img)) \n",
    "      #+ ' and ' + str(min(list_num_training_img))\n",
    "\n",
    "#Plotting bar chart of training images by bird class\n",
    "#fig, ax = plt.subplots(figsize = (15, 4))\n",
    "#sns.barplot(x = list_bird_classes,y = list_num_training_img)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf554b",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c3df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b42f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                2799375   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,818,767\n",
      "Trainable params: 2,818,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cd766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ebf6a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/68 [==========================>...] - ETA: 29s - loss: 2.3383 - accuracy: 0.2986"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1040/1583875260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Batch size and number of epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Batch size and number of epochs\n",
    "\n",
    "history = model.fit(train_data, batch_size = batch_size, epochs = epochs, validation_data = valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data, batch_size = batch_size)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and export model (if needed)\n",
    "#model.save_weights('CNN_model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracies\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification matrix\n",
    "preds = np.round(model.predict(test_data),0) \n",
    "print('rounded test_labels', preds)\n",
    "\n",
    "classification_metrics = metrics.classification_report(test_data.classes, preds, target_names = bird_classes )\n",
    "print(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "categorical_test_labels = pd.DataFrame(test_data.classes).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(preds).idxmax(axis=1)\n",
    "confusion_matrix= confusion_matrix(categorical_test_labels, categorical_preds)\n",
    "#To get better visual of the confusion matrix:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "#     print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix, ['butterflies', 'chickens', 'elephants', 'horses', 'spiders', 'squirells'],\n",
    "                     normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction test on images\n",
    "def read_image(file_path):\n",
    "    print(\"[INFO] loading and preprocessing image...\")  \n",
    "    image = load_img(file_path, target_size=(224, 224))  \n",
    "    image = img_to_array(image)  \n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image /= 255.  \n",
    "    return image\n",
    "def test_single_image(path):\n",
    "    animals = ['butterflies', 'chickens', 'elephants', 'horses', 'spiders', 'squirells']\n",
    "    images = read_image(path)\n",
    "    time.sleep(.5)\n",
    "    bt_prediction = vgg16.predict(images)  \n",
    "    preds = model.predict_proba(bt_prediction)\n",
    "    for idx, animal, x in zip(range(0,6), animals , preds[0]):\n",
    "        print(\"ID: {}, Label: {} {}%\".format(idx, animal, round(x*100,2) ))\n",
    "    print('Final Decision:')\n",
    "    time.sleep(.5)\n",
    "    for x in range(3):\n",
    "        print('.'*(x+1))\n",
    "        time.sleep(.2)\n",
    "    class_predicted = model.predict_classes(bt_prediction)\n",
    "    class_dictionary = generator_top.class_indices  \n",
    "    inv_map = {v: k for k, v in class_dictionary.items()}  \n",
    "    print(\"ID: {}, Label: {}\".format(class_predicted[0], inv_map[class_predicted[0]]))  \n",
    "    return load_img(path)\n",
    "path = 'data/test/butterears2.jpg'\n",
    "test_single_image(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728243bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a2626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
